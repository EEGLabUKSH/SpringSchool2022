# Basics of Data Analysis in R 
# Springschool Day 1, March 2022
# Merle Schuckart (merle.schuckart@gmx.de)

# ----------------------------------------------------------------
# Description of this script:

# This script will walk you through a very simple 
# data analysis (reading in data, preprocessing, stats & plotting).

# Description of the data used herein:
# The data we're analyzing here are from a simple experiment 
# in which I tried to replicate the redundant 
# signals effect (RSE). The RSE is a well-known effect, 
# according to which a participant should react faster to 
# multisensory stimuli than to unisensory ones.

# All files used herein are test data generated by me, 
# so no worries about privacy concerns here. 

# There are 3 datasets from minors (Ari, Uzi & Buckley Tenenbaum).
# The datasets of Richie, Uzi & Buckley Tenenbaum should contain a lot of missing data.

# All datasets contain information on gender, 
# age and id as well as the experimental data (RTs = "duration").
# The experiment was conducted offline using a lab.js study.

# Variables: 
# A = 1 unisensory audio-stimulus
# V = 1 unisensory visual stimulus
# VA = 1 mutisensory audio-visual stimulus

# ----------------------------------------------------------------

# 1. Settings: 

# turn off scientific notation
options(scipen = 999)

# clear environment
remove(list = ls())

# create a list with needed libraries
pkgs <- c("ggplot2", # for plots
          "car", # for Shapiro-Wilk-Test
          "ez") # for ANOVA
# load each listed library, check if it's already installed 
# and install if necessary
for (pkg in pkgs){
  if(!require(pkg, character.only = TRUE)){
    install.packages(pkg)
    library(pkg, character.only = TRUE)
  }
}

# ----------------------------------------------------------------

# 2. Load data and do some preprocessing

# 2.1 set working directory (= path to the file your data are in)
# set your own path here:
setwd('/Users/merle/Desktop/RSE_data') 
# Please notice we're always using normal slashes /, 
# backslashes \ don't work here.
# -> Have an eye on this if you're a Windows user!

# 2.2 Get the list of files in the directory
file_list <- list.files(pattern='.csv')

# 2.3 Loop through files to read in data

# 2.3.1
# Create empty dataframes as placeholder for 
# the df where you collect all our data & 
# one for the demographic information
df_data <- data.frame() 
df_demographics <- data.frame()

# 2.3.2 loop datasets aka participants:
for (i in 1:length(file_list)) { # for the number of files in our directory...
  
  # 2.3.2.1 Get dataframe for one participant
  subj_df <- read.csv(file_list[i], sep = ",")

  # Find out in which row we have to look for the demographics:
  row_demogr <- which(subj_df$sender == "Hello") # find the row where sender is Hello
  
  # 2.3.2.2 Get participant id (in our case: Name)
  # --> Don't forget the comma in the bracket!
  id <- subj_df[row_demogr, ]$id # get value where column name is "code" and row name is Demographics
  
  # 2.3.2.3 Get age 
  age <- subj_df[row_demogr, ]$age # get value where column name is "age" and row name is Demographics
  
  # 2.3.2.4 Get gender (even shorter!)
  gender <- subj_df[row_demogr, ]$gender

  # 2.3.2.6 If person is a minor, the data should be 
  # excluded from further analysis.
  # For now, we just mark them so we can exclude them later
  if (age < 18) { 
    exclude_participant <- T
  } else {
    exclude_participant <- F
  }
  
  # We could also use multiple conditions to exclude people. 
  # For example, we could exclude all people who didn't state their gender or are 
  # female:
  #if (gender == "female" | gender == "no_ans") { 
  #  exclude_participant <- T
  #} else {
  #  exclude_participant <- F
  #}
 
  # But we don't care about gender here, so let's keep them all.
  
  
  # 2.3.2.7 Now get data (RTs and condition names):
  
  # get position of column with reaction times (durations) and condition names
  col_cond <- which(names(subj_df) == "condition")
  col_RTs <- which(names(subj_df) == "duration")
  # get only a part of subj_df
  RT_data <- subset(subj_df, sender == "Reaction")[c(col_cond, col_RTs)] # get only a part of subj_df
  # RT_data is now a matrix with 2 columns, but we have to covert it to a dataframe
  RT_data <- as.data.frame(RT_data)
  
  # uncomment this line and run it to have a look at your df:
  #View(RT_data)
  
  # You can see that the column with the reaction times is still called 
  # "duration" as in the original csv file, so we rename it:
  names(RT_data) <- c("condition", "reaction_time")
  
  # exclude all trials in which the reaction time is either 
  # too short (< 100 ms) or too long (> 700 ms).
  # If the participant didn't react, the RT is 1500 ms, 
  # so we kick non-reactions out as well with these criteria.
  RT_data_clean <- subset(RT_data, reaction_time >= 100 & reaction_time <= 700)
  
  # how many trials did we exclude because they were too short or too long?
  trials_excluded <- length(RT_data$reaction_time) - length(RT_data_clean$reaction_time)
  
  # If the participant always reacted too slow or didn't 
  # react in general (in this case the RT is saved as 1500 ms aka too long),
  # we need to exclude them, too.
  if (length(RT_data_clean$reaction_time) < 80){
    exclude_participant <- T
  }
  
  # 2.3.2.8 Create 2 dfs: 
  # One with demographic information & number of excluded trials, 
  # one with the RT-data, conditions and IDs.
  
  # df 1:
  # combine all information we collected about the participant in a
  # df consisting of 1 row and 8 columns 
  dem <- as.data.frame(cbind(id, age, gender, 
                             exclude_participant, trials_excluded))
  # add to big df with all participants as new row, so there's 1 row for each participant
  df_demographics <- as.data.frame(rbind(df_demographics, dem))
  
  
  # df 2: 
  # create a vector that contains the subject ID, but repeat it 
  # so there's 1 value for each row in RT_data_clean:
  participant_ID <- c(rep(id, times = length(RT_data_clean$condition)))
  # append the ID vector to RT_data_clean 
  RT_data_clean <- as.data.frame(cbind(participant_ID, RT_data_clean))
  # append RT_data_clean to big df containing data from all participants
  df_data <- as.data.frame(rbind(df_data, RT_data_clean))
  
} # END loop files in directory  

# 2.3.3 clean up a bit: 
# remove everything from environment except for the things we still need
#rm(list = setdiff(ls(), c("df_data", "df_demographics")))

# Uncomment this to have a look at your dataframes: 
#View(df_data)
#View(df_demographics)

# 2.3.4 Now exclude all participants who were marked before as to be excluded:
pos_excl <- which(df_demographics$exclude_participant == T)
# get their codes 
id_excl <- df_demographics[pos_excl,]$id
# copy df_data and name the copy df_data_clean
df_data_clean <- df_data
# loop ids, only get subset of df_data_clean 
# where the id is not the id we want to exclude
for (id in id_excl){
  df_data_clean <- subset(df_data_clean, participant_ID != id)
}

# If we now check the unique IDs left in df_data_clean, we don't see 
# "Richie Tenenbaum", "Ari Tenenbaum", "Uzi Tenenbaum" and
# "Buckley Tenenbaum" anymore. 
# Uncomment to have a look:
unique(df_data_clean$participant_ID)

# ----------------------------------------------------------------
# 3. descriptive stats

# Now we perform summary stats for the descriptive part of your paper:

# 3.1 Get median RT of RTs for each participant in each 
# of the 3 conditions (A, V and VA):

# aggregate data:

agg_data = aggregate(df_data_clean$reaction_time,
                     by = list(df_data_clean$participant_ID, 
                               df_data_clean$condition),
                     FUN = median)

SD = aggregate(df_data_clean$reaction_time,
                     by = list(df_data_clean$participant_ID, 
                               df_data_clean$condition),
                     FUN = sd)$x
# bind them together
agg_data <- as.data.frame(cbind(agg_data, SD))

# name columns:
names(agg_data) <- c("ID", "condition", "median_RT", "SD")


# 3.2 Get median RT and SD of RTs in each of the 3 conditions (A, V and VA):

# We can use the median RTs in agg_data to compare our groups statistically, 
# but we also need means & sds for each condition aggregated over all participants
# for a table in our paper, so create another aggregated df:

# aggregate data:
agg_conditions = aggregate(df_data_clean$reaction_time,
                           by = list(df_data_clean$condition),
                           FUN = median)

# get SD as well:
SD = aggregate(df_data_clean$reaction_time,
               by = list(df_data_clean$condition),
               FUN = sd)$x

# append to agg_conditions as additional column:
agg_conditions <- as.data.frame(cbind(agg_conditions, SD))

# correct the column names: 
names(agg_conditions) <- c("Condition", "Median RT", "SD")

# Have a look: Our hypotheses were that 
# 1. the RTs in the multisensory condition VA should be a little faster than in A and V 
# 2. the RTs in V should be faster than in A. 
# Looks good!
# View(agg_conditions)

# ----------------------------------------------------------------
# 4. inferential stats 

# Hint: We always use an alpha level of 5%,
# so if we get p-values of <= 0.05, our test was significant! Yikes.

# 4.1 Shapiro-Wilk Test
# We have a super small sample, but we 
# test the distribution anyway so you know how to do it:
# Compute Kolmogorov-Smirnov-Lilliefors-Test for normality of distribution 
# If we get a significant result for one of the groups, 
# this means we don't have normality of distribution 
# and we have to test non-parametrical.

# If we don't get significant results, we can use 
# parametrical tests (e.g. ANOVAs and t-tests).
shapiro.test(subset(agg_data, condition == "A")$median_RT)
# p = 0.9596, so not significant --> maybe normally distributed

shapiro.test(subset(agg_data, condition == "VA")$median_RT)
# p = 0.5634, so not significant --> maybe normally distributed

shapiro.test(subset(agg_data, condition == "V")$median_RT)
# p = 0.3818, so not significant --> maybe normally distributed

# 4.2 Levene Test
# Normality of distribution is probably given, 
# so check homogeneity of variance (--> Levene test) and sphericity (Mauchly's test)
leveneTest(data = agg_data, median_RT ~ as.factor(condition))
# p = 0.1289, aka not significant --> use parametrical tests


# 4.3 ANOVA
# Is there a difference between the RTs in A, V and VA?
ANOVA_res <- ezANOVA(data = agg_data,
                     dv = median_RT, # dv = dependent variable = AV
                     wid = ID, # case identifier = ID
                     within = condition) # independent variable = UV

# The ezANOVA function is super useful because it 
# computes the Mauchly test (--> test for sphericity) 
# for us as well. If the Mauchly test is significant, 
# we need to use a Greenhouse-Geisser corrected p-value.
# Don't worry about this, the ezANOVA gives us 
# corrected p-value as well, so we only have to check if we need 
# to report the corrected or the uncorrected one. Easy peasy! ;-) 

# If the Mauchly test was not significant, get uncorrected values:
if (ANOVA_res$`Mauchly's Test for Sphericity`$p > 0.05){
  p_val <- ANOVA_res$`Sphericity Corrections`$`p[GG]`
} else {
  p_val <- ANOVA_res$ANOVA$p
}

# Get the test statistic F and the degrees of freedom as well
F_val <- ANOVA_res$ANOVA$`F`
# save degrees of freedom values as 1 string
df <- paste(as.character(ANOVA_res$ANOVA$DFn), ", ", as.character(ANOVA_res$ANOVA$DFd), sep = "")

# round values a bit!
p_val <- round(p_val, digits = 3)
F_val <- round(F_val, digits = 3)

# Save the results in a new dataframe!
df_results <- as.data.frame(cbind("ANOVA", "A, V & VA", p_val, F_val, df))

# Our ANOVA was significant, so we can now use post-hoc t-tests to 
# find out which groups are significantly different.


# 4.4 Post-hoc tests! 
# (use t-tests for dependent groups)

# 4.4.1 Difference between V and VA: Is RT in V > VA?
ttest_V_VA <- t.test(subset(agg_data, condition == "V")$median_RT, # H1: is > than...
                     subset(agg_data, condition == "VA")$median_RT, 
                     alternative = "greater",
                     paired = T, # dependent sample, so T
                     exact = F)
# get results:
p_val <- round(ttest_V_VA$p.value * 3, digits = 3) # Bonferroni-Holm correction for multiple comparisons
# p-value = 0.0002847662 aka significant difference here!
F_val <- round(ttest_V_VA$statistic, digits = 3)
df <- ttest_V_VA$parameter 

# add to results df! 
df_results <- as.data.frame(rbind(df_results, cbind("t-Test", "V > VA", p_val, F_val, df)))


# 4.4.2 Difference between A and VA: Is RT in A > VA?
ttest_A_VA <- t.test(subset(agg_data, condition == "A")$median_RT, # H1: is > than...
                     subset(agg_data, condition == "VA")$median_RT, 
                     alternative = "greater",
                     paired = T, # dependent sample, so T
                     exact = F)
# get results:
p_val <- round(ttest_A_VA$p.value * 3, digits = 3) # Bonferroni-Holm correction for multiple comparisons
# p-value = 0.00002211934 aka significant difference here!
F_val <- round(ttest_A_VA$statistic, digits = 3)
df <- ttest_A_VA$parameter 

# add to results df! 
df_results <- as.data.frame(rbind(df_results, cbind("t-Test", "A > VA", p_val, F_val, df)))


# 4.4.3 Difference between A and V: Is RT in A > V?
ttest_A_V <- t.test(subset(agg_data, condition == "A")$median_RT, # H1: is > than...
                    subset(agg_data, condition == "V")$median_RT, 
                    alternative = "greater",
                    paired = T, # dependent sample, so T
                    exact = F)
# get results:
p_val <- round(ttest_A_V$p.value * 3, digits = 3) # Bonferroni-Holm correction for multiple comparisons
# p-value = 0.0003423333 aka significant difference here!
F_val <- round(ttest_A_V$statistic, digits = 3)
df <- ttest_A_V$parameter 

# add to results df! 
df_results <- as.data.frame(rbind(df_results, cbind("t-Test", "A > V", p_val, F_val, df)))

# Now we want to plot our results so the world can see all this glory.

# ----------------------------------------------------------------
# 5. Plots

# You can use this website to get pretty colors for your plot:
# https://www.color-hex.com/

my_plot <- ggplot(agg_data, aes(x = condition, 
                                y = median_RT, 
                                color = condition, 
                                alpha = 1)) + # alpha = opacity
  # add boxplot:
  geom_boxplot(width = 0.3, aes(alpha = 0.1)) +
  # add scatterplot:
  geom_jitter(aes(alpha = 0.5), 
              position = position_jitter(0.1), 
              size = 2) +
  # change axis limits, so the y axis starts at 0:
  ylim(0, 350) +
  # rename axis labels
  ylab(label = "median reaction time (ms)") +
  xlab(label = "stimulus condition") +
  # set title
  ggtitle("Hello People! \n Look at me, I'm a plot!") + # you can make a linebreak by using \n
  # set font size for axis labels:
  theme(axis.title.x = element_text(size = 14), 
        axis.text.x = element_text(size=14),
        axis.title.y = element_text(size = 14), 
        axis.text.y = element_text(size=14),
        plot.title = element_text(size=20, hjust = 0.5)) +
  # set colors manually (you can also use pre-made color 
  # palettes, e.g. from the colorbrewer package)
  scale_color_manual(values =  c("#00b159", "#00aedb", "#ffc425")) +
  # turn off legend:
  theme(legend.position = "none") + 
  # turn off lines and grey background color, 
  # so the background is white:
  theme(panel.grid.major = element_blank(), 
        panel.grid.minor = element_blank(),
        panel.background = element_blank(), 
        axis.line = element_line(colour = "black")) 

# View plot
my_plot

# This is just an example, you can build more 
# or less anything you want in ggplot2. 

# There are also a lot of cool examples for plots 
# on the internet, most of them with code you can copy 
# --> check out pirateplots from the yarrr package or the R Graph Gallery: 
# https://www.r-graph-gallery.com/ggplot2-package.html
